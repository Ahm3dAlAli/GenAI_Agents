{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "add overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "add motivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key components\n",
    "\n",
    "add key components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method details\n",
    "\n",
    "add method details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "add conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet arxiv google-search-results>=2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain.pydantic_v1 import BaseModel, Field, root_validator \n",
    "from serpapi import GoogleScholarSearch\n",
    "from typing import Any\n",
    "\n",
    "# Write Google Scholar API Wrapper\n",
    "# NOTE: Langchain has a built in tool but it doesn't work\n",
    "class GoogleScholarAPIWrapper(BaseModel):\n",
    "    top_k_results: int = Field(description = \"top k results obtained by running a query on GoogleScholarSearch\")\n",
    "    serp_api_key: str | None = None\n",
    "    search_engine: Any | None = None\n",
    "\n",
    "    @root_validator(pre = True)\n",
    "    def validate_env(cls, values: dict) -> dict:\n",
    "        serp_api_key = values.get('serp_api_key')\n",
    "        if serp_api_key is None:\n",
    "            serp_api_key = os.environ[\"SERP_API_KEY\"]\n",
    "        GoogleScholarSearch.SERP_API_KEY = serp_api_key \n",
    "        values['search_engine'] = GoogleScholarSearch\n",
    "        return values\n",
    "        \n",
    "    def run(self, query: str) -> str:\n",
    "        page = 0\n",
    "        all_results = []\n",
    "        while page < max((self.top_k_results - 20), 1):\n",
    "            results = (self.search_engine({\"q\": query, \"start\": page, \"hl\": \"en\",\n",
    "                        \"num\": min(self.top_k_results, 20), \"lr\": \"lang_en\"}).get_dict().get(\"organic_results\", []))\n",
    "            all_results.extend(results)\n",
    "            if not results:  \n",
    "                break\n",
    "            page += 20\n",
    "        if (self.top_k_results % 20 != 0 and page > 20 and all_results):  # From the last page we would only need top_k_results%20 results\n",
    "            results = (self.search_engine({\"q\": query,\"start\": page,\"num\": self.top_k_results % 20, \"hl\": \"en\", \"lr\": \"lang_en\"})\n",
    "                .get_dict()\n",
    "                .get(\"organic_results\", []))\n",
    "            all_results.extend(results)\n",
    "        if not all_results:\n",
    "            return \"No good Google Scholar Result was found\"\n",
    "        docs = [\n",
    "            f\"Title: {result.get('title','')}\\n\"\n",
    "            f\"Authors: {','.join([author.get('name') for author in result.get('publication_info',{}).get('authors',[])])}\\n\"  # noqa: E501\n",
    "            f\"Summary: {result.get('publication_info',{}).get('summary','')}\\n\"\n",
    "            f\"Total-Citations: {result.get('inline_links',{}).get('cited_by',{}).get('total','')}\"\n",
    "            f\"Link: {result.get('resources',[{}])[0].get('link','')}\"\n",
    "            for result in all_results\n",
    "        ]\n",
    "        return \"\\n\\n\".join(docs)\n",
    "\n",
    "class GoogleScholarSearchInput(BaseModel):\n",
    "    query: str = Field(description=\"The query to search for on arxiv. If the query is in the form of arxiv identifier, it will return the paper corresponding to the arxiv identifier. Otherwise, it will search for the paper using the query.\")\n",
    "    max_papers: int = Field(description=\"The maximum number of papers to return. It's default to 1, but you can increase it up to 10 in case you need to perform a more comprehensive search.\", default=1, ge=1, le=10)\n",
    "\n",
    "\n",
    "class ArxivSearchInput(BaseModel):\n",
    "    id: str = Field(description=\"The arxiv id of the paper to search for.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"google-scholar-search\", args_schema=GoogleScholarSearchInput)\n",
    "def google_scholar_search(input: str) -> str:\n",
    "    \"\"\"Academic search on google scholar.\n",
    "\n",
    "    Example:\n",
    "    {\"query\": \"Attention is all you need\", \"max_papers\": 1}\n",
    "\n",
    "    Returns:\n",
    "        A list of the relevant papers found with the corresponding summaries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        input_obj = GoogleScholarSearchInput(**json.loads(input))\n",
    "        return GoogleScholarAPIWrapper(top_k_results=input_obj.max_papers).run(input_obj.query)\n",
    "    except Exception as e:\n",
    "        return f\"Error performing google scholar search: {e}\"\n",
    "\n",
    "@tool(\"arxiv-search\", args_schema=ArxivSearchInput)\n",
    "def arxiv_search(input: str) -> str:\n",
    "    \"\"\"Search for one specific scientific paper on arxiv.\n",
    "\n",
    "    Example:\n",
    "    {\"id\": \"2411.05749\"}\n",
    "\n",
    "    Returns:\n",
    "        A list of the summaries of the papers.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        input_obj = ArxivSearchInput(**json.loads(input))\n",
    "        arxiv_api_wrapper = ArxivAPIWrapper(\n",
    "            top_k_results=1,\n",
    "            load_max_docs=100,\n",
    "            ARXIV_MAX_QUERY_LENGTH=1000,  # NOTE: can be chosen better based on the model. we can also summarize it in the tool to make it more scalable\n",
    "            doc_content_chars_max=10000,  # NOTE: can be chosen better based on the model. if the overall content length is too long, we should handle it somehow  # ? summarization? truncate?\n",
    "            load_all_available_meta=True,\n",
    "        )\n",
    "        if not arxiv_api_wrapper.is_arxiv_identifier(input_obj.id):\n",
    "            raise ValueError(\"The arxiv id is not valid\")\n",
    "        \n",
    "        return arxiv_api_wrapper.run(input_obj.id)\n",
    "    except Exception as e:\n",
    "        return f\"Error performing arxiv search: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vins/miniconda3/envs/genai-agents/lib/python3.11/site-packages/langsmith/client.py:312: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write agent prompt\n",
    "# TODO: Move to langgraph\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "tools = [google_scholar_search, arxiv_search]\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=20,\n",
    "    max_execution_time=180,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Input:** what is the arxiv paper with id 1409.2329 about? provide a detailed summary of the content\n",
      "**Output:** The arXiv paper with ID 1409.2329 is titled \"Recurrent Neural Network Regularization\" and was published on February 19, 2015. It presents a regularization technique specifically for Recurrent Neural Networks (RNNs) that utilize Long Short-Term Memory (LSTM) units. The authors, Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals, discuss the limitations of the dropout technique, which is commonly used for regularizing neural networks, in the context of RNNs and LSTMs. They propose a method for correctly applying dropout to LSTMs, demonstrating that this approach significantly reduces overfitting across various tasks, including language modeling, speech recognition, image caption generation, and machine translation.\n",
      "--------------------------------------------\n",
      "**Input:** list all the authors of the paper 'Attention is all you need'?\n",
      "**Output:** The authors of the paper \"Attention is all you need\" are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin.\n",
      "--------------------------------------------\n",
      "**Input:** can you find me 8 papers on quantum machine learning?\n",
      "**Output:** 1. **Quantum machine learning**  \n",
      "   Authors: J Biamonte, P Wittek, N Pancotti, P Rebentrost  \n",
      "   Summary: Overview of quantum machine learning concepts and applications.  \n",
      "   [Link](https://arxiv.org/pdf/1611.09347)  \n",
      "\n",
      "2. **Challenges and opportunities in quantum machine learning**  \n",
      "   Authors: M Cerezo, G Verdon, HY Huang, L Cincio  \n",
      "   Summary: Discusses the current challenges and potential opportunities in the field.  \n",
      "   [Link](https://arxiv.org/pdf/2303.09491)  \n",
      "\n",
      "3. **An introduction to quantum machine learning**  \n",
      "   Authors: M Schuld, I Sinayskiy, F Petruccione  \n",
      "   Summary: A foundational introduction to the principles of quantum machine learning.  \n",
      "   [Link](https://arxiv.org/pdf/1409.3097)  \n",
      "\n",
      "4. **Power of data in quantum machine learning**  \n",
      "   Authors: HY Huang, M Mohseni  \n",
      "   Summary: Explores the significance of data in enhancing quantum machine learning algorithms.  \n",
      "   [Link](https://www.nature.com/articles/s41467-021-22539-9.pdf)  \n",
      "\n",
      "5. **Quantum machine learning: a classical perspective**  \n",
      "   Authors: C Ciliberto, M Herbster, AD Ialongo  \n",
      "   Summary: Examines quantum machine learning from a classical viewpoint.  \n",
      "   [Link](https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2017.0551?download=true)  \n",
      "\n",
      "6. **Recent advances in quantum machine learning**  \n",
      "   Authors: Q Ni  \n",
      "   Summary: Reviews recent developments and breakthroughs in quantum machine learning.  \n",
      "   [Link not provided]  \n",
      "\n",
      "7. **Quantum machine learning in feature Hilbert spaces**  \n",
      "   Authors: M Schuld, N Killoran  \n",
      "   Summary: Investigates the application of quantum machine learning in feature Hilbert spaces.  \n",
      "   [Link](https://arxiv.org/pdf/1803.07128)  \n",
      "\n",
      "8. **Systematic literature review: Quantum machine learning and its applications**  \n",
      "   Authors: D Peral-García, J Cruz-Benito  \n",
      "   Summary: A comprehensive review of the literature on quantum machine learning and its various applications.  \n",
      "   [Link](https://www.sciencedirect.com/science/article/pii/S1574013724000030)\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"what is the arxiv paper with id 1409.2329 about? provide a detailed summary of the content\",\n",
    "    \"list all the authors of the paper 'Attention is all you need'?\",\n",
    "    \"can you find me 8 papers on quantum machine learning?\",\n",
    "\n",
    "]\n",
    "\n",
    "for test_input in test_inputs:\n",
    "    out = agent_executor.invoke(\n",
    "        {\n",
    "        \"input\": test_input,\n",
    "        }   \n",
    "    )\n",
    "    print(f\"**Input:** {test_input}\")\n",
    "    print(f\"**Output:** {out['output']}\")\n",
    "    print(\"--------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
